{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6aa14b4-c4c0-44a2-b18e-aa60bfd4f88c",
   "metadata": {},
   "source": [
    "## Gaze Analysis from FacesDir JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "652168ff-1d58-4928-bd0f-892a8dae10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import shutil\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd9db57-80e7-44cc-bbcf-a35d46618012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Config ---\n",
    "FPS = int(1800/120) #frame number in chunk / chunk duration\n",
    "base_path = Path(\"/home/liubov/Desktop/BNF/work\")\n",
    "directory = '8-5-2024_#18_INDIVIDUAL_[12]'\n",
    "json_folder = 'FacesDir'\n",
    "directory_path = base_path / directory / json_folder\n",
    "directory_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "mapping_csv = base_path / directory / \"first_id_mapping_camera_a.csv\"\n",
    "\n",
    "# --- Read mapping ---\n",
    "mapping_df = pd.read_csv(mapping_csv)\n",
    "mapping_df.drop(columns='Unnamed: 0', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6fecc6-066b-401f-a664-a56a59fe6f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading camera mapping from: /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/first_id_mapping_camera_a.csv\n",
      "Camera mapping loaded with 18 entries\n",
      "Mapping columns: ['frame_number', 'original_id', 'updated_id']\n",
      "Processing directory: /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir\n",
      "Using columns frame_number -> original_id for ID to camera mapping\n",
      "ID to camera mapping: {1800: 3, 3600: 3, 5400: 3, 7200: 3, 9000: 3, 10800: 3}\n",
      "Found 8 chunk directories\n",
      "Processing chunk directory: chunk_01_00120-00240s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_01_00120-00240s/2.tar.gz (ID: 2)...\n",
      "  Extracted 1801 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_01_00120-00240s/3.tar.gz (ID: 3)...\n",
      "  Extracted 1801 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_01_00120-00240s/1.tar.gz (ID: 1)...\n",
      "  Extracted 1801 JSON files for ID 1\n",
      "Processing chunk directory: chunk_00_00000-00120s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_00_00000-00120s/2.tar.gz (ID: 2)...\n",
      "  Extracted 1801 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_00_00000-00120s/3.tar.gz (ID: 3)...\n",
      "  Extracted 1801 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_00_00000-00120s/1.tar.gz (ID: 1)...\n",
      "  Extracted 1801 JSON files for ID 1\n",
      "Processing chunk directory: chunk_05_00600-00720s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_05_00600-00720s/2.tar.gz (ID: 2)...\n",
      "  Extracted 1801 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_05_00600-00720s/3.tar.gz (ID: 3)...\n",
      "  Extracted 1801 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_05_00600-00720s/1.tar.gz (ID: 1)...\n",
      "  Extracted 1801 JSON files for ID 1\n",
      "Processing chunk directory: chunk_06_00720-00785s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_06_00720-00785s/2.tar.gz (ID: 2)...\n",
      "  Extracted 986 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_06_00720-00785s/3.tar.gz (ID: 3)...\n",
      "  Extracted 986 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_06_00720-00785s/1.tar.gz (ID: 1)...\n",
      "  Extracted 986 JSON files for ID 1\n",
      "Processing chunk directory: chunk_04_00480-00600s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_04_00480-00600s/2.tar.gz (ID: 2)...\n",
      "  Extracted 1801 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_04_00480-00600s/3.tar.gz (ID: 3)...\n",
      "  Extracted 1801 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_04_00480-00600s/1.tar.gz (ID: 1)...\n",
      "  Extracted 1801 JSON files for ID 1\n",
      "Processing chunk directory: chunk_02_00240-00360s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_02_00240-00360s/2.tar.gz (ID: 2)...\n",
      "  Extracted 1801 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_02_00240-00360s/3.tar.gz (ID: 3)...\n",
      "  Extracted 1801 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_02_00240-00360s/1.tar.gz (ID: 1)...\n",
      "  Extracted 1801 JSON files for ID 1\n",
      "Processing chunk directory: chunk_03_00360-00480s\n",
      "Debug: Processing archive '2.tar' from file '2.tar.gz'\n",
      "Debug: Extracted ID 2 from '2.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_03_00360-00480s/2.tar.gz (ID: 2)...\n",
      "  Extracted 1801 JSON files for ID 2\n",
      "Debug: Processing archive '3.tar' from file '3.tar.gz'\n",
      "Debug: Extracted ID 3 from '3.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_03_00360-00480s/3.tar.gz (ID: 3)...\n",
      "  Extracted 1801 JSON files for ID 3\n",
      "Debug: Processing archive '1.tar' from file '1.tar.gz'\n",
      "Debug: Extracted ID 1 from '1.tar'\n",
      "Extracting face data from /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/chunk_03_00360-00480s/1.tar.gz (ID: 1)...\n",
      "  Extracted 1801 JSON files for ID 1\n",
      "Total face JSON files collected: 35376\n",
      "ID 2: 11792 face detection files\n",
      "ID 3: 11792 face detection files\n",
      "ID 1: 11792 face detection files\n",
      "Processing ID 2 (Camera: unknown_camera_2) - 11792 files...\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "✓ Merged 11785 face JSON files for ID 2 -> /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces/faces_id_2_camera_unknown_camera_2_merged.json\n",
      "Processing ID 3 (Camera: unknown_camera_3) - 11792 files...\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "✓ Merged 11785 face JSON files for ID 3 -> /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces/faces_id_3_camera_unknown_camera_3_merged.json\n",
      "Processing ID 1 (Camera: unknown_camera_1) - 11792 files...\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "Unexpected error processing /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/edges.json: unsupported operand type(s) for /: 'NoneType' and 'int'\n",
      "✓ Merged 11785 face JSON files for ID 1 -> /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces/faces_id_1_camera_unknown_camera_1_merged.json\n",
      "\n",
      "Created 3 merged face files, one for each participant ID\n",
      "Detailed summary saved to /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces/face_detection_detailed_summary.csv\n",
      "Face detection summary saved to /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces/face_detection_summary.json\n",
      "\n",
      "All 35376 intermediate face JSON files removed.\n",
      "Only final merged files remain.\n",
      "\n",
      "============================================================\n",
      "FACE PROCESSING COMPLETE\n",
      "============================================================\n",
      "Configuration:\n",
      "  - FPS: 15\n",
      "  - Directory: 8-5-2024_#18_INDIVIDUAL_[12]\n",
      "  - Base path: /home/liubov/Desktop/BNF/work\n",
      "  - JSON folder: FacesDir\n",
      "\n",
      "Results:\n",
      "  ID 1 (Camera unknown_camera_1): 11792 frames, 0 with faces (0.0%), avg 0.0 faces/frame\n",
      "  ID 2 (Camera unknown_camera_2): 11792 frames, 0 with faces (0.0%), avg 0.0 faces/frame\n",
      "  ID 3 (Camera unknown_camera_3): 11792 frames, 0 with faces (0.0%), avg 0.0 faces/frame\n",
      "\n",
      "Output files created in: /home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces\n",
      "  - 3 merged JSON files\n",
      "  - 1 summary statistics file\n",
      "  - 1 detailed CSV file\n"
     ]
    }
   ],
   "source": [
    "# --- Config ---\n",
    "FPS = int(1800/120)  # frame number in chunk / chunk duration\n",
    "base_path = Path(\"/home/liubov/Desktop/BNF/work\")\n",
    "directory = '8-5-2024_#18_INDIVIDUAL_[12]'\n",
    "json_folder = 'FacesDir'\n",
    "directory_path = base_path / directory / json_folder\n",
    "directory_path.mkdir(parents=True, exist_ok=True)\n",
    "mapping_csv = base_path / directory / \"first_id_mapping_camera_a.csv\"\n",
    "\n",
    "# --- Read mapping ---\n",
    "print(f\"Reading camera mapping from: {mapping_csv}\")\n",
    "mapping_df = pd.read_csv(mapping_csv)\n",
    "if 'Unnamed: 0' in mapping_df.columns:\n",
    "    mapping_df.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "print(f\"Camera mapping loaded with {len(mapping_df)} entries\")\n",
    "print(f\"Mapping columns: {list(mapping_df.columns)}\")\n",
    "print(f\"Processing directory: {directory_path}\")\n",
    "\n",
    "# Create ID to camera mapping dictionary\n",
    "# Assuming the CSV has columns like 'camera_id', 'participant_id', or similar\n",
    "# Adjust these column names based on your actual CSV structure\n",
    "try:\n",
    "    if 'camera_id' in mapping_df.columns and 'participant_id' in mapping_df.columns:\n",
    "        id_to_camera = dict(zip(mapping_df['participant_id'], mapping_df['camera_id']))\n",
    "    elif 'id' in mapping_df.columns and 'camera' in mapping_df.columns:\n",
    "        id_to_camera = dict(zip(mapping_df['id'], mapping_df['camera']))\n",
    "    else:\n",
    "        # Fallback: use first two columns\n",
    "        cols = mapping_df.columns[:2]\n",
    "        id_to_camera = dict(zip(mapping_df[cols[0]], mapping_df[cols[1]]))\n",
    "        print(f\"Using columns {cols[0]} -> {cols[1]} for ID to camera mapping\")\n",
    "    \n",
    "    print(f\"ID to camera mapping: {id_to_camera}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating mapping: {e}\")\n",
    "    id_to_camera = {}\n",
    "\n",
    "# ---------------- 1. Extract tar.gz and flatten Face JSONs ----------------\n",
    "face_files_with_id = []  # List of tuples: (file_path, archive_id)\n",
    "chunk_dirs = [d for d in directory_path.iterdir() if d.is_dir()]\n",
    "\n",
    "print(f\"Found {len(chunk_dirs)} chunk directories\")\n",
    "\n",
    "for chunk_dir in chunk_dirs:\n",
    "    tar_files = list(chunk_dir.glob(\"*.tar.gz\"))\n",
    "    if not tar_files:\n",
    "        continue\n",
    "    \n",
    "    print(f\"Processing chunk directory: {chunk_dir.name}\")\n",
    "    \n",
    "    for tar_file in tar_files:\n",
    "        # Extract ID from archive name (e.g., \"1.tar.gz\" -> ID 1)\n",
    "        archive_name = tar_file.stem  # removes .tar.gz\n",
    "        archive_name = archive_name.strip()  # Remove any whitespace\n",
    "        \n",
    "        print(f\"Debug: Processing archive '{archive_name}' from file '{tar_file.name}'\")\n",
    "        \n",
    "        try:\n",
    "            archive_id = int(archive_name)\n",
    "        except ValueError:\n",
    "            # Try to extract number from more complex names\n",
    "            number_match = re.search(r'(\\d+)', archive_name)\n",
    "            if number_match:\n",
    "                archive_id = int(number_match.group(1))\n",
    "                print(f\"Debug: Extracted ID {archive_id} from '{archive_name}'\")\n",
    "            else:\n",
    "                print(f\"Warning: Could not extract ID from archive name '{tar_file.name}', skipping...\")\n",
    "                continue\n",
    "            \n",
    "        print(f\"Extracting face data from {tar_file} (ID: {archive_id})...\")\n",
    "        extract_dir = chunk_dir / f\"{tar_file.stem}_extracted\"\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        try:\n",
    "            with tarfile.open(tar_file, \"r:gz\") as tar:\n",
    "                for member in tar.getmembers():\n",
    "                    member.path = Path(member.name).name  # flatten\n",
    "                    tar.extract(member, path=extract_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting {tar_file}: {e}\")\n",
    "            continue\n",
    "            \n",
    "        # Look for JSON files (face detection results)\n",
    "        json_count = 0\n",
    "        for jf in extract_dir.rglob(\"*.json\"):\n",
    "            final_path = directory_path / jf.name\n",
    "            if final_path.exists():\n",
    "                final_path.unlink()\n",
    "            shutil.move(str(jf), final_path)\n",
    "            face_files_with_id.append((final_path, archive_id))\n",
    "            json_count += 1\n",
    "            \n",
    "        print(f\"  Extracted {json_count} JSON files for ID {archive_id}\")\n",
    "            \n",
    "        # Cleanup extracted folder\n",
    "        for f in extract_dir.rglob(\"*\"):\n",
    "            if f.is_file():\n",
    "                f.unlink()\n",
    "        if extract_dir.exists():\n",
    "            extract_dir.rmdir()\n",
    "\n",
    "print(f\"Total face JSON files collected: {len(face_files_with_id)}\")\n",
    "\n",
    "# ---------------- 2. Sort face JSON files by frame number within each ID ----------------\n",
    "def get_frame_number_from_face_file(file_path):\n",
    "    \"\"\"Extract frame number from face detection JSON filename\"\"\"\n",
    "    name = file_path.name.strip()\n",
    "    # Look for patterns like frame_000001.json, 000001.json, etc.\n",
    "    frame_patterns = [\n",
    "        r'frame_(\\d+)\\.json$',\n",
    "        r'(\\d+)\\.json$',\n",
    "        r'face_(\\d+)\\.json$',\n",
    "        r'faces_(\\d+)\\.json$'\n",
    "    ]\n",
    "    \n",
    "    for pattern in frame_patterns:\n",
    "        m = re.search(pattern, name)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    \n",
    "    return float('inf')\n",
    "\n",
    "def frame_to_timestamp(frame_number, fps=FPS):\n",
    "    \"\"\"Convert frame number to timestamp in seconds\"\"\"\n",
    "    return frame_number / fps if fps > 0 else 0\n",
    "\n",
    "# Group files by archive ID\n",
    "faces_by_id = {}\n",
    "for file_path, archive_id in face_files_with_id:\n",
    "    if archive_id not in faces_by_id:\n",
    "        faces_by_id[archive_id] = []\n",
    "    faces_by_id[archive_id].append(file_path)\n",
    "\n",
    "# Sort files by frame number within each ID group\n",
    "for id_key in faces_by_id:\n",
    "    faces_by_id[id_key].sort(key=get_frame_number_from_face_file)\n",
    "    print(f\"ID {id_key}: {len(faces_by_id[id_key])} face detection files\")\n",
    "\n",
    "# ---------------- 3. Merge Face JSONs by archive ID with enhanced metadata ----------------\n",
    "def parse_face_filename_info(file_path):\n",
    "    \"\"\"Extract frame number from face detection filename\"\"\"\n",
    "    frame_value = get_frame_number_from_face_file(file_path)\n",
    "    return frame_value if frame_value != float('inf') else None\n",
    "\n",
    "merged_faces_folder = directory_path / \"merged_faces\"\n",
    "merged_faces_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# Create merged file for each archive ID\n",
    "for archive_id, file_list in faces_by_id.items():\n",
    "    merged_face_data = []\n",
    "    camera_id = id_to_camera.get(archive_id, f\"unknown_camera_{archive_id}\")\n",
    "    \n",
    "    print(f\"Processing ID {archive_id} (Camera: {camera_id}) - {len(file_list)} files...\")\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                frame_value = parse_face_filename_info(file_path)\n",
    "                timestamp = frame_to_timestamp(frame_value, FPS)\n",
    "                \n",
    "                # Enhanced metadata for face data\n",
    "                metadata = {\n",
    "                    'participant_id': archive_id,\n",
    "                    'camera_id': camera_id,\n",
    "                    'frame_number': frame_value,\n",
    "                    'timestamp_seconds': timestamp,\n",
    "                    'fps': FPS,\n",
    "                    'source_file': file_path.name\n",
    "                }\n",
    "                \n",
    "                # Inject metadata into face data\n",
    "                if isinstance(data, dict):\n",
    "                    data.update(metadata)\n",
    "                    # If there are detected faces, add metadata to each face\n",
    "                    if 'faces' in data and isinstance(data['faces'], list):\n",
    "                        for i, face in enumerate(data['faces']):\n",
    "                            if isinstance(face, dict):\n",
    "                                face.update(metadata)\n",
    "                                face['face_id'] = f\"{archive_id}_{frame_value}_{i}\"\n",
    "                    elif 'detections' in data and isinstance(data['detections'], list):\n",
    "                        for i, detection in enumerate(data['detections']):\n",
    "                            if isinstance(detection, dict):\n",
    "                                detection.update(metadata)\n",
    "                                detection['face_id'] = f\"{archive_id}_{frame_value}_{i}\"\n",
    "                                \n",
    "                elif isinstance(data, list):\n",
    "                    # If data is a list of face detections\n",
    "                    for i, entry in enumerate(data):\n",
    "                        if isinstance(entry, dict):\n",
    "                            entry.update(metadata)\n",
    "                            entry['face_id'] = f\"{archive_id}_{frame_value}_{i}\"\n",
    "                \n",
    "                merged_face_data.append(data)\n",
    "                \n",
    "        except (json.JSONDecodeError, UnicodeDecodeError) as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Create output file for this archive ID\n",
    "    output_file = merged_faces_folder / f\"faces_id_{archive_id}_camera_{camera_id}_merged.json\"\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(merged_face_data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✓ Merged {len(merged_face_data)} face JSON files for ID {archive_id} -> {output_file}\")\n",
    "\n",
    "print(f\"\\nCreated {len(faces_by_id)} merged face files, one for each participant ID\")\n",
    "\n",
    "# ---------------- 4. Create enhanced summary statistics ----------------\n",
    "summary_file = merged_faces_folder / \"face_detection_summary.json\"\n",
    "detailed_summary_file = merged_faces_folder / \"face_detection_detailed_summary.csv\"\n",
    "\n",
    "summary_stats = {}\n",
    "detailed_records = []\n",
    "\n",
    "for archive_id, file_list in faces_by_id.items():\n",
    "    camera_id = id_to_camera.get(archive_id, f\"unknown_camera_{archive_id}\")\n",
    "    total_frames = len(file_list)\n",
    "    frames_with_faces = 0\n",
    "    total_faces_detected = 0\n",
    "    max_faces_in_frame = 0\n",
    "    \n",
    "    # Count faces across all frames for this ID\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                faces_in_frame = 0\n",
    "                \n",
    "                if isinstance(data, dict):\n",
    "                    if 'faces' in data and isinstance(data['faces'], list):\n",
    "                        faces_in_frame = len(data['faces'])\n",
    "                    elif 'detections' in data and isinstance(data['detections'], list):\n",
    "                        faces_in_frame = len(data['detections'])\n",
    "                elif isinstance(data, list):\n",
    "                    faces_in_frame = len(data)\n",
    "                \n",
    "                if faces_in_frame > 0:\n",
    "                    frames_with_faces += 1\n",
    "                    total_faces_detected += faces_in_frame\n",
    "                    max_faces_in_frame = max(max_faces_in_frame, faces_in_frame)\n",
    "                    \n",
    "                # Add to detailed records\n",
    "                frame_number = get_frame_number_from_face_file(file_path)\n",
    "                detailed_records.append({\n",
    "                    'participant_id': archive_id,\n",
    "                    'camera_id': camera_id,\n",
    "                    'frame_number': frame_number,\n",
    "                    'timestamp_seconds': frame_to_timestamp(frame_number, FPS),\n",
    "                    'faces_detected': faces_in_frame,\n",
    "                    'source_file': file_path.name\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path} for summary: {e}\")\n",
    "            continue\n",
    "    \n",
    "    avg_faces_per_frame = total_faces_detected / frames_with_faces if frames_with_faces > 0 else 0\n",
    "    \n",
    "    summary_stats[f\"id_{archive_id}\"] = {\n",
    "        \"participant_id\": archive_id,\n",
    "        \"camera_id\": camera_id,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"frames_with_faces\": frames_with_faces,\n",
    "        \"total_faces_detected\": total_faces_detected,\n",
    "        \"max_faces_in_frame\": max_faces_in_frame,\n",
    "        \"avg_faces_per_frame\": round(avg_faces_per_frame, 2),\n",
    "        \"face_detection_rate\": round(frames_with_faces / total_frames, 4) if total_frames > 0 else 0,\n",
    "        \"fps_config\": FPS\n",
    "    }\n",
    "\n",
    "# Save summary statistics\n",
    "with open(summary_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summary_stats, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "# Save detailed CSV\n",
    "if detailed_records:\n",
    "    detailed_df = pd.DataFrame(detailed_records)\n",
    "    detailed_df.to_csv(detailed_summary_file, index=False)\n",
    "    print(f\"Detailed summary saved to {detailed_summary_file}\")\n",
    "\n",
    "print(f\"Face detection summary saved to {summary_file}\")\n",
    "\n",
    "# ---------------- 5. Cleanup intermediate JSONs ----------------\n",
    "all_face_files = []\n",
    "for file_list in faces_by_id.values():\n",
    "    all_face_files.extend(file_list)\n",
    "\n",
    "for file_path in all_face_files:\n",
    "    if file_path.exists():\n",
    "        file_path.unlink()\n",
    "\n",
    "print(f\"\\nAll {len(all_face_files)} intermediate face JSON files removed.\")\n",
    "print(\"Only final merged files remain.\")\n",
    "\n",
    "# ---------------- 6. Final Report ----------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FACE PROCESSING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  - FPS: {FPS}\")\n",
    "print(f\"  - Directory: {directory}\")\n",
    "print(f\"  - Base path: {base_path}\")\n",
    "print(f\"  - JSON folder: {json_folder}\")\n",
    "print(f\"\\nResults:\")\n",
    "for archive_id in sorted(faces_by_id.keys()):\n",
    "    stats = summary_stats[f\"id_{archive_id}\"]\n",
    "    camera = stats['camera_id']\n",
    "    print(f\"  ID {archive_id} (Camera {camera}): {stats['total_frames']} frames, \"\n",
    "          f\"{stats['frames_with_faces']} with faces ({stats['face_detection_rate']:.1%}), \"\n",
    "          f\"avg {stats['avg_faces_per_frame']:.1f} faces/frame\")\n",
    "\n",
    "print(f\"\\nOutput files created in: {merged_faces_folder}\")\n",
    "print(f\"  - {len(faces_by_id)} merged JSON files\")\n",
    "print(f\"  - 1 summary statistics file\")\n",
    "print(f\"  - 1 detailed CSV file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91cb6cc-bdb4-4a13-a5e3-2691e170961c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     gaze_right_3d     gaze_left_3d gaze_averaged_angle_3d  \\\n",
      "0  [0.0, 0.0, 0.0]  [0.0, 0.0, 0.0]             [0.0, 0.0]   \n",
      "1  [0.0, 0.0, 0.0]  [0.0, 0.0, 0.0]             [0.0, 0.0]   \n",
      "2  [0.0, 0.0, 0.0]  [0.0, 0.0, 0.0]             [0.0, 0.0]   \n",
      "3  [0.0, 0.0, 0.0]  [0.0, 0.0, 0.0]             [0.0, 0.0]   \n",
      "4  [0.0, 0.0, 0.0]  [0.0, 0.0, 0.0]             [0.0, 0.0]   \n",
      "\n",
      "                              eye_right_keypoints_2d  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                               eye_left_keypoints_2d  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                              eye_right_keypoints_3d  \\\n",
      "0  [-512.0, -288.0, 699.9, -512.4, -288.2, 700.5,...   \n",
      "1  [-512.0, -288.0, 699.9, -512.4, -288.2, 700.5,...   \n",
      "2  [-512.0, -288.0, 699.9, -512.4, -288.2, 700.5,...   \n",
      "3  [-512.0, -288.0, 699.9, -512.4, -288.2, 700.5,...   \n",
      "4  [-512.0, -288.0, 699.9, -512.4, -288.2, 700.5,...   \n",
      "\n",
      "                               eye_left_keypoints_3d                       R  \\\n",
      "0  [-511.6, -287.8, 699.5, -512.2, -288.1, 700.2,...  [-0.367, 0.451, 0.015]   \n",
      "1  [-511.6, -287.8, 699.5, -512.2, -288.1, 700.2,...  [-0.367, 0.451, 0.015]   \n",
      "2  [-511.6, -287.8, 699.5, -512.2, -288.1, 700.2,...  [-0.367, 0.451, 0.015]   \n",
      "3  [-511.6, -287.8, 699.5, -512.2, -288.1, 700.2,...  [-0.367, 0.451, 0.015]   \n",
      "4  [-511.6, -287.8, 699.5, -512.2, -288.1, 700.2,...  [-0.367, 0.451, 0.015]   \n",
      "\n",
      "                                        t  \\\n",
      "0  [-28757728.0, -16176221.0, 39317204.0]   \n",
      "1  [-28757728.0, -16176221.0, 39317204.0]   \n",
      "2  [-28757728.0, -16176221.0, 39317204.0]   \n",
      "3  [-28757728.0, -16176221.0, 39317204.0]   \n",
      "4  [-28757728.0, -16176221.0, 39317204.0]   \n",
      "\n",
      "                                   face_keypoints_2d  ...  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  ...   \n",
      "\n",
      "             pdm_rigid_parameters  \\\n",
      "0  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "1  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "2  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "3  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "4  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]   \n",
      "\n",
      "                            pdm_non_rigid_parameters  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                  action_units_score  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                 action_units_binary participant_id  \\\n",
      "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...              1   \n",
      "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...              1   \n",
      "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...              1   \n",
      "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...              1   \n",
      "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...              1   \n",
      "\n",
      "          camera_id frame_number  timestamp_seconds  fps           source_file  \n",
      "0  unknown_camera_1            0                0.0   15   00000000000000.json  \n",
      "1  unknown_camera_1            0                0.0   15   00000000000000.json  \n",
      "2  unknown_camera_1            0                0.0   15   00000000000000.json  \n",
      "3  unknown_camera_1            0                0.0   15   00000000000000.json  \n",
      "4  unknown_camera_1            0                0.0   15   00000000000000.json  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "filepath = '/home/liubov/Desktop/BNF/work/8-5-2024_#18_INDIVIDUAL_[12]/FacesDir/merged_faces/faces_id_1_camera_unknown_camera_1_merged.json'\n",
    "\n",
    "with open(filepath, 'r') as f:\n",
    "    data = json.load(f)  \n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f1392ab-7f94-488e-994a-224a27a31fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"camera_id\", \"fps\", \"source_file\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b91bdd17-c97d-4c13-95df-b3f260f1241c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gaze_right_3d', 'gaze_left_3d', 'gaze_averaged_angle_3d',\n",
       "       'eye_right_keypoints_2d', 'eye_left_keypoints_2d',\n",
       "       'eye_right_keypoints_3d', 'eye_left_keypoints_3d', 'R', 't',\n",
       "       'face_keypoints_2d', 'face_keypoints_3d', 'pdm_rigid_parameters',\n",
       "       'pdm_non_rigid_parameters', 'action_units_score', 'action_units_binary',\n",
       "       'participant_id', 'frame_number', 'timestamp_seconds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4320b35-b04b-49a0-986d-3191ee905bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns\n",
    "# Index(['gaze_right_3d', 'gaze_left_3d', 'gaze_averaged_angle_3d',\n",
    "#        'eye_right_keypoints_2d', 'eye_left_keypoints_2d',\n",
    "#        'eye_right_keypoints_3d', 'eye_left_keypoints_3d', 'R', 't',\n",
    "#        'face_keypoints_2d', 'face_keypoints_3d', 'pdm_rigid_parameters',\n",
    "#        'pdm_non_rigid_parameters', 'action_units_score', 'action_units_binary',\n",
    "#        'participant_id', 'frame_number', 'timestamp_seconds'],\n",
    "#       dtype='object')\n",
    "# len(df.eye_right_keypoints_2d.loc[0])=56\n",
    "# len(df.eye_right_keypoints_3d.loc[0])=84\n",
    "#df.R.value_counts() [-0.367, 0.451, 0.015]    11785 Name: count, dtype: int64 Looks like the same for all rows\n",
    "# df.t.value_counts() t [-28757728.0, -16176221.0, 39317204.0]    11785 Name: count, dtype: int64\n",
    "# df.face_keypoints_2d.value_counts() [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...]    11785\n",
    "# df.face_keypoints_3d.value_counts() face_keypoints_3d  [-546.9, -307.6, 747.7, -545.6,  -493.0, ...]    11785  Name: count, dtype: int64\n",
    "# df.pdm_rigid_parameters.value_counts() [1.0, 0.0, 0.0, 0.0, 0.0, 0.0]    11785 Name: count, dtype: int64\n",
    "# pdm_non_rigid_parameters [0.0, 0.0, 0.0, 0.0, 0.0, 0.0,... 0.0, 0.0, 0.0, 0.0, 0.0]    11785\n",
    "# action_units_score [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]    11785 Name: count, dtype: int64 \n",
    "# action_units_binary [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]    11785 Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1f22a-062a-48f8-b836-20f85fbefc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
