{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6aa14b4-c4c0-44a2-b18e-aa60bfd4f88c",
   "metadata": {},
   "source": [
    "## Gaze Analysis from FacesDir JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd12b201-68e1-4838-9c2f-6612c59814a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing data mapping...\n",
      "Mapping prepared using hardcoded values.\n",
      "\n",
      "Step 1: Extracting and flattening JSONs from archives...\n",
      "Extracted a total of 35376 JSON files.\n",
      "\n",
      "Step 2: Merging JSON data per participant...\n",
      "Created 3 merged files.\n",
      "\n",
      "Step 3: Computing summary statistics...\n",
      "Summary statistics computed.\n",
      "\n",
      "Step 4: Cleaning up intermediate files...\n",
      "Intermediate files removed.\n",
      "\n",
      "Step 5: Loading data into DataFrames and computing gaze metrics...\n",
      "Gaze metrics computed and attention log created.\n",
      "\n",
      "Step 6: Aggregating dwell times...\n",
      "Dwell times aggregated.\n",
      "\n",
      "============================================================\n",
      "FINAL ANALYSIS REPORT\n",
      "============================================================\n",
      "Summary of Face Detection:\n",
      "  ID 1 (Camera Camera_A): 11792 frames, 11792 with faces (100.0%), avg 1.0 faces/frame\n",
      "  ID 2 (Camera Camera_B): 11792 frames, 11792 with faces (100.0%), avg 1.0 faces/frame\n",
      "  ID 3 (Camera Camera_C): 11792 frames, 11792 with faces (100.0%), avg 1.0 faces/frame\n",
      "\n",
      "Patient_1 Gaze Dwell Time on Others:\n",
      "  - Therapist_1: 786.13 s (100.0%)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract + flatten JSONs from tar archives.\n",
    "# Step 2: Merge JSONs per participant with metadata.\n",
    "# Step 3: Load merged JSONs into nested DataFrames.\n",
    "# Step 4: Compute gaze vectors and nearest-person attention.\n",
    "# Step 5: Aggregate dwell time per participant.\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import math\n",
    "import re\n",
    "import tarfile\n",
    "import shutil\n",
    "\n",
    "# --- Config ---\n",
    "FPS = int(1800 / 120)  # frames per second\n",
    "base_path = Path(\"/home/liubov/Bureau/new\")\n",
    "directory = '8-5-2024_#18_INDIVIDUAL_[12]/processed by chunks'\n",
    "json_folder = 'FacesDir'\n",
    "directory_path = base_path / directory / json_folder\n",
    "mapping_csv = base_path / directory / \"first_id_mapping_camera_a.csv\"\n",
    "\n",
    "# --- Load mapping ---\n",
    "print(\"Loading and preparing data mapping...\")\n",
    "try:\n",
    "    # Use a hardcoded mapping to ensure correct IDs\n",
    "    manual_mapping = {'1': 'Patient_1', '2': 'Therapist_1', '3': 'Therapist_2'}\n",
    "    mapping_df = pd.DataFrame(manual_mapping.items(), columns=['original_id', 'updated_id'])\n",
    "\n",
    "    # Create ID to camera mapping based on hardcoded values\n",
    "    id_to_camera = {1: 'Camera_A', 2: 'Camera_B', 3: 'Camera_C'} # Assuming a simple camera mapping\n",
    "    print(\"Mapping prepared using hardcoded values.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error creating ID to camera mapping: {e}\")\n",
    "    id_to_camera = {}\n",
    "    mapping_df = pd.DataFrame(columns=['original_id', 'updated_id'])\n",
    "\n",
    "# ---------------- 1. Extract tar.gz and flatten Face JSONs ----------------\n",
    "print(\"\\nStep 1: Extracting and flattening JSONs from archives...\")\n",
    "face_files_with_id = []\n",
    "chunk_dirs = [d for d in directory_path.iterdir() if d.is_dir()]\n",
    "\n",
    "for chunk_dir in chunk_dirs:\n",
    "    for tar_file in chunk_dir.glob(\"*.tar.gz\"):\n",
    "        archive_name = tar_file.stem.strip()\n",
    "        try:\n",
    "            archive_id = int(archive_name)\n",
    "        except ValueError:\n",
    "            number_match = re.search(r'(\\d+)', archive_name)\n",
    "            if number_match:\n",
    "                archive_id = int(number_match.group(1))\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        extract_dir = chunk_dir / f\"{tar_file.stem}_extracted\"\n",
    "        extract_dir.mkdir(exist_ok=True)\n",
    "        try:\n",
    "            with tarfile.open(tar_file, \"r:gz\") as tar:\n",
    "                for member in tar.getmembers():\n",
    "                    member.path = Path(member.name).name\n",
    "                    tar.extract(member, path=extract_dir)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        for jf in extract_dir.rglob(\"*.json\"):\n",
    "            final_path = directory_path / jf.name\n",
    "            if final_path.exists():\n",
    "                final_path.unlink()\n",
    "            shutil.move(str(jf), final_path)\n",
    "            face_files_with_id.append((final_path, archive_id))\n",
    "\n",
    "        shutil.rmtree(extract_dir)\n",
    "print(f\"Extracted a total of {len(face_files_with_id)} JSON files.\")\n",
    "\n",
    "# ---------------- 2. Merge JSONs per participant with metadata ----------------\n",
    "def get_frame_number_from_face_file(file_path):\n",
    "    name = file_path.name.strip()\n",
    "    frame_patterns = [\n",
    "        r'frame_(\\d+)\\.json$', r'(\\d+)\\.json$', r'face_(\\d+)\\.json$', r'faces_(\\d+)\\.json$'\n",
    "    ]\n",
    "    for pattern in frame_patterns:\n",
    "        m = re.search(pattern, name)\n",
    "        if m:\n",
    "            return int(m.group(1))\n",
    "    return float('inf')\n",
    "\n",
    "def frame_to_timestamp(frame_number, fps=FPS):\n",
    "    return frame_number / fps if fps > 0 else 0\n",
    "\n",
    "print(\"\\nStep 2: Merging JSON data per participant...\")\n",
    "faces_by_id = {}\n",
    "for file_path, archive_id in face_files_with_id:\n",
    "    if archive_id not in faces_by_id:\n",
    "        faces_by_id[archive_id] = []\n",
    "    faces_by_id[archive_id].append(file_path)\n",
    "\n",
    "for id_key in faces_by_id:\n",
    "    faces_by_id[id_key].sort(key=get_frame_number_from_face_file)\n",
    "\n",
    "merged_faces_folder = directory_path / \"merged_faces\"\n",
    "merged_faces_folder.mkdir(exist_ok=True)\n",
    "\n",
    "for archive_id, file_list in faces_by_id.items():\n",
    "    merged_face_data = []\n",
    "    camera_id = id_to_camera.get(archive_id, f\"unknown_camera_{archive_id}\")\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                frame_value = get_frame_number_from_face_file(file_path)\n",
    "                timestamp = frame_to_timestamp(frame_value, FPS)\n",
    "                metadata = {\n",
    "                    'participant_id': archive_id,\n",
    "                    'camera_id': camera_id,\n",
    "                    'frame_number': frame_value,\n",
    "                    'timestamp_seconds': timestamp,\n",
    "                    'fps': FPS,\n",
    "                    'source_file': file_path.name\n",
    "                }\n",
    "                if isinstance(data, dict):\n",
    "                    data.update(metadata)\n",
    "                    if 'faces' in data and isinstance(data['faces'], list):\n",
    "                        for i, face in enumerate(data['faces']):\n",
    "                            if isinstance(face, dict):\n",
    "                                face.update(metadata)\n",
    "                                face['face_id'] = f\"{archive_id}_{frame_value}_{i}\"\n",
    "                    elif 'detections' in data and isinstance(data['detections'], list):\n",
    "                        for i, detection in enumerate(data['detections']):\n",
    "                            if isinstance(detection, dict):\n",
    "                                detection.update(metadata)\n",
    "                                detection['face_id'] = f\"{archive_id}_{frame_value}_{i}\"\n",
    "                    # This is the new check for the specific file format you provided\n",
    "                    elif 'face_keypoints_3d' in data and isinstance(data['face_keypoints_3d'], list) and len(data['face_keypoints_3d']) > 0:\n",
    "                        data['face_id'] = f\"{archive_id}_{frame_value}_0\"\n",
    "                elif isinstance(data, list):\n",
    "                    for i, entry in enumerate(data):\n",
    "                        if isinstance(entry, dict):\n",
    "                            entry.update(metadata)\n",
    "                            entry['face_id'] = f\"{archive_id}_{frame_value}_{i}\"\n",
    "                merged_face_data.append(data)\n",
    "        except (json.JSONDecodeError, UnicodeDecodeError, Exception):\n",
    "            continue\n",
    "    if merged_face_data:\n",
    "        output_file = merged_faces_folder / f\"faces_id_{archive_id}_camera_{camera_id}_merged.json\"\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(merged_face_data, f, indent=4, ensure_ascii=False)\n",
    "print(f\"Created {len(faces_by_id)} merged files.\")\n",
    "\n",
    "# ---------------- 3. Compute and save summary statistics ----------------\n",
    "print(\"\\nStep 3: Computing summary statistics...\")\n",
    "summary_stats = {}\n",
    "for archive_id, file_list in faces_by_id.items():\n",
    "    camera_id = id_to_camera.get(archive_id, f\"unknown_camera_{archive_id}\")\n",
    "    total_frames = len(file_list)\n",
    "    frames_with_faces = 0\n",
    "    total_faces_detected = 0\n",
    "    max_faces_in_frame = 0\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "                faces_in_frame = 0\n",
    "                if isinstance(data, dict):\n",
    "                    if 'faces' in data and isinstance(data['faces'], list):\n",
    "                        faces_in_frame = len(data['faces'])\n",
    "                    elif 'detections' in data and isinstance(data['detections'], list):\n",
    "                        faces_in_frame = len(data['detections'])\n",
    "                    # This is the new logic to handle your file format\n",
    "                    elif 'face_keypoints_3d' in data and isinstance(data['face_keypoints_3d'], list) and len(data['face_keypoints_3d']) > 0:\n",
    "                        faces_in_frame = 1 # We assume one face per file in this format\n",
    "                elif isinstance(data, list):\n",
    "                    faces_in_frame = len(data)\n",
    "                if faces_in_frame > 0:\n",
    "                    frames_with_faces += 1\n",
    "                    total_faces_detected += faces_in_frame\n",
    "                    max_faces_in_frame = max(max_faces_in_frame, faces_in_frame)\n",
    "        except Exception:\n",
    "            continue\n",
    "    avg_faces_per_frame = total_faces_detected / frames_with_faces if frames_with_faces > 0 else 0\n",
    "    summary_stats[f\"id_{archive_id}\"] = {\n",
    "        \"participant_id\": archive_id,\n",
    "        \"camera_id\": camera_id,\n",
    "        \"total_frames\": total_frames,\n",
    "        \"frames_with_faces\": frames_with_faces,\n",
    "        \"total_faces_detected\": total_faces_detected,\n",
    "        \"max_faces_in_frame\": max_faces_in_frame,\n",
    "        \"avg_faces_per_frame\": round(avg_faces_per_frame, 2),\n",
    "        \"face_detection_rate\": round(frames_with_faces / total_frames, 4) if total_frames > 0 else 0,\n",
    "        \"fps_config\": FPS\n",
    "    }\n",
    "print(\"Summary statistics computed.\")\n",
    "\n",
    "# ---------------- 4. Cleanup intermediate JSONs ----------------\n",
    "print(\"\\nStep 4: Cleaning up intermediate files...\")\n",
    "all_face_files = [file for file_list in faces_by_id.values() for file in file_list]\n",
    "for file_path in all_face_files:\n",
    "    if file_path.exists():\n",
    "        file_path.unlink()\n",
    "print(\"Intermediate files removed.\")\n",
    "\n",
    "# ---------------- 5. Load merged JSONs into nested DataFrames and compute gaze vectors ----------------\n",
    "print(\"\\nStep 5: Loading data into DataFrames and computing gaze metrics...\")\n",
    "def load_and_process(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    df = pd.DataFrame(data)\n",
    "    for col in [\"camera_id\", \"fps\", \"source_file\"]:\n",
    "        if col in df.columns:\n",
    "            df.drop(columns=col, inplace=True)\n",
    "    keypoint_cols = [\"eye_right_keypoints_3d\", \"eye_left_keypoints_3d\", \"face_keypoints_3d\"]\n",
    "    \n",
    "    def make_tuple_list(values):\n",
    "        if not isinstance(values, list) or not values:\n",
    "            return []\n",
    "        \n",
    "        # Check if the list contains a nested list or tuple, which is the error\n",
    "        if isinstance(values[0], (list, tuple)):\n",
    "            # Flatten the list if it's nested\n",
    "            flat_list = [item for sublist in values for item in sublist]\n",
    "        else:\n",
    "            flat_list = values\n",
    "        \n",
    "        if len(flat_list) % 3 != 0:\n",
    "            return []\n",
    "            \n",
    "        return [(flat_list[i], flat_list[i+1], flat_list[i+2]) for i in range(0, len(flat_list), 3)]\n",
    "\n",
    "    processed = pd.DataFrame()\n",
    "    for col in keypoint_cols:\n",
    "        processed[col] = df[col].apply(make_tuple_list)\n",
    "    processed[\"participant_id\"] = df[\"participant_id\"]\n",
    "    processed[\"frame_number\"] = df[\"frame_number\"]\n",
    "    processed[\"timestamp_seconds\"] = df[\"timestamp_seconds\"]\n",
    "    return processed\n",
    "\n",
    "merged_folder = directory_path / \"merged_faces\"\n",
    "all_jsons = list(merged_folder.glob(\"*.json\"))\n",
    "processed_dfs = {}\n",
    "\n",
    "mapping_dict = dict(zip(mapping_df['original_id'], mapping_df['updated_id']))\n",
    "for original_id_str, updated_id_str in mapping_dict.items():\n",
    "    try:\n",
    "        original_id_int = int(original_id_str)\n",
    "        matched_files = [f for f in all_jsons if f\"faces_id_{original_id_int}_\" in f.name]\n",
    "        if matched_files:\n",
    "            processed_dfs[updated_id_str] = load_and_process(matched_files[0])\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eye_center(eye_landmarks):\n",
    "    if not eye_landmarks:\n",
    "        return np.array([0.0, 0.0, 0.0])\n",
    "    return np.mean(np.array(eye_landmarks), axis=0)\n",
    "\n",
    "def compute_gaze_vector(eye_landmarks, face_landmarks):\n",
    "    eye_center = compute_eye_center(eye_landmarks)\n",
    "    \n",
    "    if not face_landmarks or len(face_landmarks) <= 30:\n",
    "        return np.array([0.0, 0.0, 0.0]), eye_center\n",
    "\n",
    "    try:\n",
    "        nose_tip = np.array(face_landmarks[30])  # adjust index as needed\n",
    "        gaze_vec = nose_tip - eye_center\n",
    "        norm = np.linalg.norm(gaze_vec)\n",
    "        if norm > 0:\n",
    "            gaze_vec /= norm\n",
    "        return gaze_vec, eye_center\n",
    "    except:\n",
    "        return np.array([0.0, 0.0, 0.0]), eye_center\n",
    "\n",
    "def nearest_person(eye_center, gaze_vec, other_faces):\n",
    "    min_dist = float(\"inf\")\n",
    "    nearest_name = None\n",
    "    for name, center in other_faces.items():\n",
    "        t = np.dot(center - eye_center, gaze_vec)\n",
    "        proj = eye_center + t * gaze_vec\n",
    "        dist = np.linalg.norm(proj - center)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            nearest_name = name\n",
    "    return nearest_name\n",
    "\n",
    "patient_id = 'Patient_1'\n",
    "if patient_id not in processed_dfs:\n",
    "    raise ValueError(f\"{patient_id} not found in processed DataFrames. Check your mapping.\")\n",
    "\n",
    "patient_df = processed_dfs[patient_id]\n",
    "frame_numbers = patient_df['frame_number'].values\n",
    "attention_log = []\n",
    "\n",
    "for idx, frame_no in enumerate(frame_numbers):\n",
    "    face_centers = {}\n",
    "    for name, df in processed_dfs.items():\n",
    "        landmarks = df['face_keypoints_3d'].iloc[idx]\n",
    "        face_centers[name] = np.mean(np.array(landmarks), axis=0) if landmarks else np.array([0.0, 0.0, 0.0])\n",
    "\n",
    "    gaze_vec_r, eye_center_r = compute_gaze_vector(\n",
    "        patient_df['eye_right_keypoints_3d'].iloc[idx],\n",
    "        patient_df['face_keypoints_3d'].iloc[idx]\n",
    "    )\n",
    "    gaze_vec_l, eye_center_l = compute_gaze_vector(\n",
    "        patient_df['eye_left_keypoints_3d'].iloc[idx],\n",
    "        patient_df['face_keypoints_3d'].iloc[idx]\n",
    "    )\n",
    "    \n",
    "    if gaze_vec_r.size == 0 or gaze_vec_l.size == 0:\n",
    "        gaze_vec = np.array([0.0, 0.0, 0.0])\n",
    "        eye_center = np.array([0.0, 0.0, 0.0])\n",
    "    else:\n",
    "        gaze_vec = (gaze_vec_r + gaze_vec_l) / 2\n",
    "        norm = np.linalg.norm(gaze_vec)\n",
    "        if norm > 0:\n",
    "            gaze_vec /= norm\n",
    "        eye_center = (eye_center_r + eye_center_l) / 2\n",
    "\n",
    "    other_faces = {k:v for k,v in face_centers.items() if k != patient_id}\n",
    "    target_person = nearest_person(eye_center, gaze_vec, other_faces)\n",
    "    attention_log.append(target_person)\n",
    "print(\"Gaze metrics computed and attention log created.\")\n",
    "\n",
    "# ---------------- 6. Aggregate dwell time per participant ----------------\n",
    "print(\"\\nStep 6: Aggregating dwell times...\")\n",
    "attention_counts = Counter(attention_log)\n",
    "attention_time_seconds = {p: c / FPS for p, c in attention_counts.items() if p is not None}\n",
    "print(\"Dwell times aggregated.\")\n",
    "\n",
    "# ---------------- Final Report ----------------\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINAL ANALYSIS REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(\"Summary of Face Detection:\")\n",
    "for archive_id in sorted(faces_by_id.keys()):\n",
    "    if f\"id_{archive_id}\" in summary_stats:\n",
    "        stats = summary_stats[f\"id_{archive_id}\"]\n",
    "        camera = stats['camera_id']\n",
    "        print(f\"  ID {archive_id} (Camera {camera}): {stats['total_frames']} frames, \"\n",
    "              f\"{stats['frames_with_faces']} with faces ({stats['face_detection_rate']:.1%}), \"\n",
    "              f\"avg {stats['avg_faces_per_frame']:.1f} faces/frame\")\n",
    "\n",
    "print(f\"\\n{patient_id} Gaze Dwell Time on Others:\")\n",
    "total_gaze_time = sum(attention_time_seconds.values())\n",
    "for p, t in attention_time_seconds.items():\n",
    "    percentage = (t / total_gaze_time) * 100 if total_gaze_time > 0 else 0\n",
    "    print(f\"  - {p}: {t:.2f} s ({percentage:.1f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb04b05-3596-4c11-9396-0c1c67570523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Participant presence across frames:\n",
      "  - Patient_1: 11792 frames\n",
      "  - Therapist_1: 11792 frames\n",
      "  - Therapist_2: 11792 frames\n"
     ]
    }
   ],
   "source": [
    "participant_presence = []\n",
    "\n",
    "for idx, frame_no in enumerate(frame_numbers):\n",
    "    visible_people = []\n",
    "    for name, df in processed_dfs.items():\n",
    "        if idx < len(df):\n",
    "            landmarks = df['face_keypoints_3d'].iloc[idx]\n",
    "            if isinstance(landmarks, list) and len(landmarks) > 0:\n",
    "                visible_people.append(name)\n",
    "    participant_presence.append((frame_no, visible_people))\n",
    "\n",
    "# Summary: how many frames included each participant?\n",
    "presence_counts = Counter([p for _, plist in participant_presence for p in plist])\n",
    "print(\"\\nParticipant presence across frames:\")\n",
    "for p, count in presence_counts.items():\n",
    "    print(f\"  - {p}: {count} frames\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b54084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaze vector standard deviation across frames: [0.1631128  0.10127666 0.30778997]\n"
     ]
    }
   ],
   "source": [
    "all_gaze_vectors = []\n",
    "for idx in range(len(frame_numbers)):\n",
    "    gaze_vec_r, _ = compute_gaze_vector(\n",
    "        patient_df['eye_right_keypoints_3d'].iloc[idx],\n",
    "        patient_df['face_keypoints_3d'].iloc[idx]\n",
    "    )\n",
    "    gaze_vec_l, _ = compute_gaze_vector(\n",
    "        patient_df['eye_left_keypoints_3d'].iloc[idx],\n",
    "        patient_df['face_keypoints_3d'].iloc[idx]\n",
    "    )\n",
    "    gaze_vec = (gaze_vec_r + gaze_vec_l) / 2\n",
    "    all_gaze_vectors.append(gaze_vec)\n",
    "\n",
    "gaze_array = np.array(all_gaze_vectors)\n",
    "print(\"Gaze vector standard deviation across frames:\", gaze_array.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b27d51c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[DEBUG] Patient_1 keypoint stats:\n",
      "  - Right Eye STD: [ 84.06365952 133.25493264 545.79022674]\n",
      "  - Left Eye STD:  [ 79.40702148 144.38493844 557.09568566]\n",
      "  - Face STD:      [ 89.12789506 150.22664782 644.61334595]\n"
     ]
    }
   ],
   "source": [
    "def compute_mean_std(keypoints_series):\n",
    "    values = []\n",
    "    for item in keypoints_series:\n",
    "        if isinstance(item, list) and item:\n",
    "            values.append(np.mean(np.array(item), axis=0))\n",
    "    values = np.array(values)\n",
    "    return values.mean(axis=0), values.std(axis=0)\n",
    "\n",
    "print(\"\\n[DEBUG] Patient_1 keypoint stats:\")\n",
    "eye_r_mean, eye_r_std = compute_mean_std(patient_df['eye_right_keypoints_3d'])\n",
    "eye_l_mean, eye_l_std = compute_mean_std(patient_df['eye_left_keypoints_3d'])\n",
    "face_mean, face_std = compute_mean_std(patient_df['face_keypoints_3d'])\n",
    "\n",
    "print(f\"  - Right Eye STD: {eye_r_std}\")\n",
    "print(f\"  - Left Eye STD:  {eye_l_std}\")\n",
    "print(f\"  - Face STD:      {face_std}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ada9237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frame 14.0\n",
      "  Eye center: [0. 0. 0.]\n",
      "  Gaze vec: [0.5697289  0.58112347 0.58112347]\n",
      "    - Therapist_1 center: [34.0952381  34.04761905 34.97619048]\n",
      "    - Therapist_2 center: [34.0952381  34.04761905 34.97619048]\n",
      "\n",
      "Frame 71.0\n",
      "  Eye center: [0. 0. 0.]\n",
      "  Gaze vec: [0.5697289  0.58112347 0.58112347]\n",
      "    - Therapist_1 center: [34.0952381  34.04761905 34.97619048]\n",
      "    - Therapist_2 center: [34.0952381  34.04761905 34.97619048]\n",
      "\n",
      "Frame 142.0\n",
      "  Eye center: [0. 0. 0.]\n",
      "  Gaze vec: [0.5697289  0.58112347 0.58112347]\n",
      "    - Therapist_1 center: [34.0952381  34.04761905 34.97619048]\n",
      "    - Therapist_2 center: [34.0952381  34.04761905 34.97619048]\n"
     ]
    }
   ],
   "source": [
    "for idx in [100, 500, 1000]:\n",
    "    print(f\"\\nFrame {frame_numbers[idx]}\")\n",
    "    print(f\"  Eye center: {eye_center}\")\n",
    "    print(f\"  Gaze vec: {gaze_vec}\")\n",
    "    for name, center in other_faces.items():\n",
    "        print(f\"    - {name} center: {center}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee40484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the same data for each participant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
